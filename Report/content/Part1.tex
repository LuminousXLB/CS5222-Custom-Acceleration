\section{Matrix Multiplication Pipeline Optimization in HLS}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Understanding the baseline matrix multiply (background)}\label{sec:1a}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For Vitis 2020.2, the command used should be
\begin{minted}{console}
    $ vitis_hls -f hls.tcl
\end{minted}
The report generated by HLS (as in \autoref{tab:loop-float_00_orig}) shows that
some pipelining has already been done automatically by Vitis HLS.
In order to prepare baseline for the next part, I disabled the pipelining.

\inputminted{diff}{program/float_nopipe.diff}

The new report is as \autoref{tab:loop-float_01_nopipe}.
It turns out that the overall performance is a little bit worse than documented.
This is because every iteration in L3 loop takes 11 cycles and thus
2816 cycles in total to perform a single inner product.

\begin{table}
    \caption{Loop details for baseline with automatic pipelining}
    \label{tab:loop-float_00_orig}
    \centering
    \input{report/loop-float_00_orig.rpt.tex}
\end{table}

\begin{table}
    \caption{Loop details for baseline without automatic pipelining}
    \label{tab:loop-float_01_nopipe}
    \centering
    \input{report/loop-float_01_nopipe.rpt.tex}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pipelining in HLS (8 marks)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The work is done with auto pipelining disabled.
The performance and utilization estimates are reported in \autoref{tab:float}.

\begin{table}
    \centering
    \caption{Performance and utilization estimates for \texttt{mmult\_float}}\label{tab:float}
    \input{report/summary.tex}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Pipelining the L3 (innermost) loop}\label{sec:1bL3}

The code is modified as \autoref{fig:float-diff.L3}.
As reported in \autoref{tab:loop-float_02_innermost}, pipelining L3 reduces its latency from 2816 cycles to 1031 cycles.
The L1 is flattened, but L2 cannot be flattened because L2 is not a perfect loop.
Thus the result has 2-layer loops where the outer layer has 80 iterations, and the inner layer has 256 iterations.
There is no parallelism in this condition.
This design utilizes slightly more resources but no more floating point adders or multipliers.
The overall latency is 85285 cycles, which is about 2.67x speedup.
Other statistics in detail can be found in \autoref{tab:float}.

\begin{figure}[h!]
    \centering
    \inputminted{diff}{program/diff.L3}
    \caption{Inserting HLS directive for L3.}\label{fig:float-diff.L3}
\end{figure}

\begin{table}[h!]
    \caption{Loop details for L3 pipelining}
    \label{tab:loop-float_02_innermost}
    \centering
    \input{report/loop-float_02_innermost.rpt.tex}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Pipelining the L2 loop}\label{sec:1bL2}

The code is modified as \autoref{fig:float-diff.L2}.
As reported in \autoref{tab:loop-float_04_L2}, pipelining the loop body of L2 unrolls L3 and introduces both pipelining and some parallelism, which reduces the iteration latency from 2816 cycles to 1287 cycles and the total latency for the matrix multiplication from 225536 to 2550.
The design used 16 adders and 16 multipliers.
The overall latency is 7341 cycles, about 31.06x speedup relative to baseline.
Other statistics in detail can be found in \autoref{tab:float}.

\begin{figure}[h!]
    \centering
    \inputminted{diff}{program/diff.L2}
    \caption{Inserting HLS directive for L2.}\label{fig:float-diff.L2}
\end{figure}

\begin{table}[h!]
    \caption{Loop details for L2 pipelining}
    \label{tab:loop-float_04_L2}
    \centering
    \input{report/loop-float_04_L2.rpt.tex}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Pipelining the L1 (outermost) loop}\label{sec:1bL1}

The code is modified as \autoref{fig:float-diff.L1}.
The loop details are in \autoref{tab:loop-float_03_outermost}.
Pipelining L1 makes both L2 and L3 completely unrolled, which makes there only one loop with 8 iterations.
The unrolled loop body is heavily paralleled, which make use of 160 floating point adders and 160 floating point multipliers.
The parallelism reduces the latency for one iteration from 28190 cycles to 1291 cycles.
The pipelining further reduce the latency for L1 to 1402 cycles, although there are eight iterations.
The overall latency is 6193 cycles, about 36.82x speedup relative to L3 pipelining and 1.19x speedup compared to L2 pipelining.
Other statistics in detail can be found in \autoref{tab:float}.

Although L1 pipelining achieves some speedup compared to L2 pipelining, it takes 299.1 seconds to complete the whole building process, while the time for L2 pipelining is only 62.5 seconds.
At the same time, the hardware resource usage has exceeded those available on board.\footnote{
    DSP (363\%), FF (390\%) , LUT (457\%)
}
Thus, L2 pipelining will be a better result after the tradeoff between performance and resource usage.

\begin{figure}[h!]
    \centering
    \inputminted{diff}{program/diff.L1}
    \caption{Inserting HLS directive for L1.}\label{fig:float-diff.L1}
\end{figure}

\begin{table}[h!]
    \caption{Loop details for L1 pipelining}
    \label{tab:loop-float_03_outermost}
    \centering
    \input{report/loop-float_03_outermost.rpt.tex}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{C. Increasing Pipeline Parallelism by Repartitioning Memories (8 marks)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Report
\begin{enumerate}
    \item the design latency in cycles,
    \item the overall device utilization (as Total per Resource),
    \item the number of floating point adders and multipliers (you can find this information under the Instance section of the synthesis report) and
    \item the Initiation Interval of the loops you pipelined.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{D. Amortizing Iteration Latency with Batching (8 marks)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Report \begin{enumerate}
    \item the design latency in cycles, and
    \item the overall device utilization (as Total per Resource).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{E. Extending Batch Size with Tiling (8 marks)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Report \begin{enumerate}
    \item the design latency in cycles, and
    \item the overall device utilization (as Total per Resource).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{F. Hardware compilation and FPGA testing on the PYNQ (8 marks)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Report
\begin{enumerate}
    \item the measured speedup and
    \item measured classification accuracy.
\end{enumerate}

